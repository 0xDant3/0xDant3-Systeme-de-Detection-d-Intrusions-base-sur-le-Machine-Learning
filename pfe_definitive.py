# -*- coding: utf-8 -*-
"""PFE_Definitive.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1USZ6g8vFaCoVD89j4p1x77wrF7nmQsVR
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report, f1_score
import seaborn as sns
from tabulate import tabulate

# Charger les données d'entraînement et de test
train = pd.read_csv('/content/Train_data.csv')

test = pd.read_csv('/content/Test_data.csv')

train.head()

train.info()

train.describe()

train.describe(include='object')

train.isnull().sum()

total = train.shape[0]
missing_columns = [col for col in train.columns if train[col].isnull().sum() > 0]
for col in missing_columns:
    null_count = train[col].isnull().sum()
    per = (null_count/total) * 100
    print(f"{col}: {null_count} ({round(per, 3)}%)")

print(f"Nombre de lignes dupliquées: {train.duplicated().sum()}")

#Visualiser la répartition des classes
sns.countplot(x=train['class'])
print("Répartition des classes dans l'ensemble d'entraînement:")
print(train['class'].value_counts())

#Encodage des étiquettes
def le(df):
    for col in df.columns:
        if df[col].dtype == 'object':
            label_encoder = LabelEncoder()
            df[col] = label_encoder.fit_transform(df[col])

le(train)

le(test)

#Preparation des donnes
test.drop(['num_outbound_cmds'], axis=1, inplace=True)

X_train = train.drop(['class'], axis=1)

Y_train = train['class']

x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, train_size=0.70, random_state=2)

#Entrainment de KNN
KNN_model = KNeighborsClassifier(n_neighbors=5)

KNN_model.fit(x_train, y_train)

#Evaluation de modèle
KNN_train, KNN_test = KNN_model.score(x_train, y_train), KNN_model.score(x_test, y_test)

print(f"Score d'entraînement: {KNN_train}")

print(f"Score de test: {KNN_test}")

#Affichage des scores du modèle
data = [["KNN", KNN_train, KNN_test]]

col_names = ["Modèle", "Score d'entraînement", "Score de test"]
print(tabulate(data, headers=col_names, tablefmt="fancy_grid"))

#Cross-validation
#est une technique utilisée en apprentissage automatique pour évaluer
#dans quelle mesure un modèle entraîné se généralise à un ensemble de
#données indépendant.
SEED = 42
knn = KNeighborsClassifier()

from sklearn.model_selection import cross_val_score
models = {}
models['KNeighborsClassifier']= knn

scores = {}
for name in models:
  scores[name]={}
  for scorer in ['precision','recall']:
    scores[name][scorer] = cross_val_score(models[name], x_train, y_train, cv=10, scoring=scorer)

# Affichage des résultats de cross-validation
def line(name):
  return '*'*(25-len(name)//2)

for name in models:
  print(line(name), name, 'Validation de modèle', line(name))

  for scorer in ['precision','recall']:
    mean = round(np.mean(scores[name][scorer])*100,2)
    stdev = round(np.std(scores[name][scorer])*100,2)
    print ("Mean {}:".format(scorer),"\n", mean,"%", "+-",stdev)
    print()

#Tracer les scores de cross-validation
for name in models:
    for scorer in ['precision','recall']:
        scores[name][scorer] = scores[name][scorer].mean()
scores=pd.DataFrame(scores).swapaxes("index", "columns")*100
scores.plot(kind = "bar",  ylim=[80,100], figsize=(24,6), rot=0)

#Prédictions du modèle
preds={}
for name in models:
    models[name].fit(x_train, y_train)
    preds[name] = models[name].predict(x_test)
print("Prédictions terminées.")

#Evaluation du modèle
def line(name,sym="*"):
    return sym*(25-len(name)//2)
target_names=["normal","anamoly"]
for name in models:
    print(line(name), name, 'Test de modèle', line(name))
    print(confusion_matrix(y_test, preds[name]))
    print(line(name,'-'))
    print(classification_report(y_test, preds[name], target_names=target_names))

#Tracer les scores de F1
f1s = {}
for name in models:
    f1s[name]=f1_score(y_test, preds[name])
f1s=pd.DataFrame(f1s.values(),index=f1s.keys(),columns=["F1-score"])*100
f1s.plot(kind = "bar",  ylim=[80,100], figsize=(10,6), rot=0)

# Function to generate synthetic DoS attack data
def simulate_dos_attack_data(num_samples, feature_space):
    # Assuming 'feature_space' is a DataFrame of the normal traffic features
    # We will generate synthetic data by introducing anomalies that mimic a DoS attack
    dos_attack_data = feature_space.sample(n=num_samples, replace=True).copy()

    # Introduce anomalies in the data
    # For example, if 'duration' is a feature, we can increase it to simulate a DoS attack
    dos_attack_data['duration'] = np.random.randint(10, 1000, size=num_samples)

    # You can introduce other types of anomalies based on known DoS attack patterns
    # ...

    # Return the synthetic DoS attack data
    return dos_attack_data

# Number of DoS attack samples you want to simulate
num_dos_samples = 100

# Simulate DoS attack data
# Make sure to use the same features as your normal traffic data
dos_features = simulate_dos_attack_data(num_dos_samples, X_train)

# Create DoS attack labels (assuming '1' is the label for attack)
dos_labels = np.ones(num_dos_samples, dtype=int)

# Add the simulated DoS attack data to the test set
x_test = pd.concat([x_test, dos_features])
y_test = np.concatenate([y_test, dos_labels])

# Now you can use your trained KNN model to predict and evaluate on this updated test set
preds = KNN_model.predict(x_test)

# Evaluate the model with the simulated DoS attack data included
print(confusion_matrix(y_test, preds))
print(classification_report(y_test, preds, target_names=target_names))

# Function to generate synthetic IP Spoofing attack data
def simulate_ip_spoofing_attack_data(num_samples, feature_space):
    # Assuming 'feature_space' is a DataFrame of the normal traffic features
    # We will generate synthetic data by introducing anomalies that mimic an IP Spoofing attack
    ip_spoofing_attack_data = feature_space.sample(n=num_samples, replace=True).copy()

    # Introduce anomalies in the data
    # For example, if 'src_bytes' and 'dst_bytes' are features, we can manipulate them
    # to simulate the traffic of an IP Spoofing attack
    ip_spoofing_attack_data['src_bytes'] = np.random.randint(1000, 10000, size=num_samples)
    ip_spoofing_attack_data['dst_bytes'] = np.random.randint(1000, 10000, size=num_samples)

    # You can introduce other types of anomalies based on known IP Spoofing attack patterns
    # ...

    # Return the synthetic IP Spoofing attack data
    return ip_spoofing_attack_data

# Number of IP Spoofing attack samples you want to simulate
num_ip_spoofing_samples = 100

# Simulate IP Spoofing attack data
# Make sure to use the same features as your normal traffic data
ip_spoofing_features = simulate_ip_spoofing_attack_data(num_ip_spoofing_samples, X_train)

# Create IP Spoofing attack labels (assuming '1' is the label for attack)
ip_spoofing_labels = np.ones(num_ip_spoofing_samples, dtype=int)

# Add the simulated IP Spoofing attack data to the test set
x_test = pd.concat([x_test, ip_spoofing_features])
y_test = np.concatenate([y_test, ip_spoofing_labels])

# Now you can use your trained KNN model to predict and evaluate on this updated test set
preds = KNN_model.predict(x_test)

# Evaluate the model with the simulated IP Spoofing attack data included
print(confusion_matrix(y_test, preds))
print(classification_report(y_test, preds, target_names=target_names))